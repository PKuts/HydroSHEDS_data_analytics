{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6d0e42",
   "metadata": {},
   "source": [
    "\n",
    "## Catchments  ## \n",
    "\n",
    "**Pour points**\n",
    "\n",
    "Definition: Specific locations on the river network where we want to measure or model water flow.\n",
    "Examples: Gauging stations, river mouths, dams, hydropower plants.\n",
    "\n",
    "**Catchments**\n",
    " \n",
    "Definition: The area of land where all rainfall drains to the same pour point.\n",
    "Each catchment is linked to exactly one pour point.\n",
    "\n",
    "**Steps**\n",
    "- Clip HydroSHEDS DEM, ACC, DIR Bhutan + buffer.\n",
    "- Create pour points (CSV with lon, lat, id).\n",
    "- Snap pour points to nearest high-ACC pixels (river cells).\n",
    "- Use flow direction (DIR) + snapped points to generate catchments.\n",
    "- Convert catchments to polygons and calculate basic attributes.\n",
    "\n",
    "\n",
    "- Use your clipped DIR (as_dir_Bhutan_and_buffer.tif) to build a catchment ID raster (one ID per basin).\n",
    "- Convert catchments to polygons (optional, for QA/visualization).\n",
    "- Build a point‚Üícatchment_id mapping for any Bhutan locations (CSV of lon/lat).\n",
    "- Use the same raster to tag every weather pixel with catchment_id, then group/aggregate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125e47ba",
   "metadata": {},
   "source": [
    "## 1. Crop and Save a Smaller DEM, ACC, DIR (TIF) for Bhutan + Buffer\n",
    "Instead of processing the full Asia-wide TIF files, we first crop and save a smaller GeoTIFF files limited to the Bhutan region and its buffer (latitude 25.0¬∞‚Äì29.5¬∞, longitude 87.0¬∞‚Äì93.5¬∞). \n",
    "\n",
    "**DEM** ‚Äî Digital Elevation Model\n",
    "\n",
    "- A raster grid of ground elevation (usually meters above sea level).\n",
    "\n",
    "**DIR** ‚Äî Flow Direction\n",
    "\n",
    "- A raster showing which neighboring cell water flows to from each cell (downslope).\n",
    "- In HydroSHEDS (ESRI D8), values encode directions: 1=E, 2=SE, 4=S, 8=SW, 16=W, 32=NW, 64=N, 128=NE. \n",
    "- Computed from the DEM.\n",
    "\n",
    "**ACC** ‚Äî Flow Accumulation\n",
    "\n",
    "- For each cell, how much upstream area drains into it.\n",
    "- High ACC = river channels; used to define streams and to snap pour points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df54dc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Number of bands in TIFF: 1\n",
      "‚úÖ Saved: ../../data/HydroSHEDS/as_dem_Bhutan_and_buffer.tif\n",
      "üìê Size (width x height): 7800.0 x 5400.0\n",
      "üíæ File size: 80.37 MB\n",
      "üìå CRS: EPSG:4326\n",
      "üß≠ Bounds: BoundingBox(left=87.0, bottom=25.000000000000007, right=93.5, top=29.500000000000007)\n",
      "üì¶ Data type: int16\n",
      "üßÆ NoData value: 32767.0\n",
      "‚úÖ Memory cleaned up.\n"
     ]
    }
   ],
   "source": [
    "#First lets cut DEM\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.enums import Resampling\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Define the input and output paths\n",
    "input_tif = \"../../data/HydroSHEDS/as_dem_3s.tif\"\n",
    "output_tif = \"../../data/HydroSHEDS/as_dem_Bhutan_and_buffer.tif\"\n",
    "\n",
    "# Define the bounding box for Bhutan + buffer (in degrees)\n",
    "min_lon, max_lon = 87.0, 93.5\n",
    "min_lat, max_lat = 25.0, 29.5\n",
    "\n",
    "# Open the source TIFF file\n",
    "with rasterio.open(input_tif) as src:\n",
    "    print(f\"üì¶ Number of bands in TIFF: {src.count}\")\n",
    "    if src.count != 1:\n",
    "        raise ValueError(\"‚ùå Expected only one band in the DEM file.\")\n",
    "\n",
    "    # Compute the pixel window corresponding to the bounding box\n",
    "    window = from_bounds(min_lon, min_lat, max_lon, max_lat, transform=src.transform)\n",
    "\n",
    "    # Read the data within that window (band 1 = elevation)\n",
    "    data = src.read(1, window=window)\n",
    "\n",
    "    # Get the updated transform for the cropped window\n",
    "    transform = src.window_transform(window)\n",
    "\n",
    "    # Save the cropped raster to a new TIF\n",
    "    out_meta = src.meta.copy()\n",
    "    out_meta.update({\n",
    "        \"height\": window.height,\n",
    "        \"width\": window.width,\n",
    "        \"transform\": transform\n",
    "    })\n",
    "\n",
    "    with rasterio.open(output_tif, \"w\", **out_meta) as out_src:\n",
    "        out_src.write(data, 1)\n",
    "\n",
    "print(f\"‚úÖ Saved: {output_tif}\")\n",
    "print(f\"üìê Size (width x height): {window.width} x {window.height}\")\n",
    "\n",
    "# Check file size in MB\n",
    "file_size_mb = os.path.getsize(output_tif) / (1024 * 1024)\n",
    "print(f\"üíæ File size: {file_size_mb:.2f} MB\")\n",
    "\n",
    "with rasterio.open(output_tif) as tif_check:\n",
    "    print(f\"üìå CRS: {tif_check.crs}\")\n",
    "    print(f\"üß≠ Bounds: {tif_check.bounds}\")\n",
    "    print(f\"üì¶ Data type: {tif_check.dtypes[0]}\")\n",
    "    print(f\"üßÆ NoData value: {tif_check.nodata}\")\n",
    "\n",
    "# üî• Clean up memory\n",
    "del data, transform, out_meta, window, tif_check, src, out_src\n",
    "gc.collect()\n",
    "print(\"‚úÖ Memory cleaned up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4de1e2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Number of bands in TIFF: 1\n",
      "‚úÖ Saved: ../../data/HydroSHEDS/as_acc_Bhutan_and_buffer.tif\n",
      "üìê Size (width x height): 7800.0 x 5400.0\n",
      "üíæ File size: 160.71 MB\n",
      "üìå CRS: EPSG:4326\n",
      "üß≠ Bounds: BoundingBox(left=87.0, bottom=25.000000000000007, right=93.5, top=29.500000000000007)\n",
      "üì¶ Data type: uint32\n",
      "üßÆ NoData value: 4294967295.0\n",
      "‚úÖ Memory cleaned up (ACC).\n",
      "üì¶ Number of bands in TIFF: 1\n",
      "‚úÖ Saved: ../../data/HydroSHEDS/as_dir_Bhutan_and_buffer.tif\n",
      "üìê Size (width x height): 7800.0 x 5400.0\n",
      "üíæ File size: 40.20 MB\n",
      "üìå CRS: EPSG:4326\n",
      "üß≠ Bounds: BoundingBox(left=87.0, bottom=25.000000000000007, right=93.5, top=29.500000000000007)\n",
      "üì¶ Data type: uint8\n",
      "üßÆ NoData value: 255.0\n",
      "‚úÖ Memory cleaned up (DIR).\n"
     ]
    }
   ],
   "source": [
    "#Cut DIR and ACC\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.enums import Resampling\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# === ACC ===\n",
    "input_tif_acc  = \"../../data/HydroSHEDS/as_acc_3s.tif\"\n",
    "output_tif_acc = \"../../data/HydroSHEDS/as_acc_Bhutan_and_buffer.tif\"\n",
    "\n",
    "# Bhutan + buffer (degrees)\n",
    "min_lon, max_lon = 87.0, 93.5\n",
    "min_lat, max_lat = 25.0, 29.5\n",
    "\n",
    "with rasterio.open(input_tif_acc) as src_acc:\n",
    "    print(f\"üì¶ Number of bands in TIFF: {src_acc.count}\")\n",
    "    if src_acc.count != 1:\n",
    "        raise ValueError(\"‚ùå Expected only one band in the ACC file.\")\n",
    "\n",
    "    window_acc = from_bounds(min_lon, min_lat, max_lon, max_lat, transform=src_acc.transform)\n",
    "\n",
    "    data_acc = src_acc.read(1, window=window_acc)\n",
    "    transform_acc = src_acc.window_transform(window_acc)\n",
    "\n",
    "    out_meta_acc = src_acc.meta.copy()\n",
    "    out_meta_acc.update({\n",
    "        \"height\": window_acc.height,\n",
    "        \"width\": window_acc.width,\n",
    "        \"transform\": transform_acc\n",
    "    })\n",
    "\n",
    "    with rasterio.open(output_tif_acc, \"w\", **out_meta_acc) as out_src_acc:\n",
    "        out_src_acc.write(data_acc, 1)\n",
    "\n",
    "print(f\"‚úÖ Saved: {output_tif_acc}\")\n",
    "print(f\"üìê Size (width x height): {window_acc.width} x {window_acc.height}\")\n",
    "\n",
    "file_size_mb_acc = os.path.getsize(output_tif_acc) / (1024 * 1024)\n",
    "print(f\"üíæ File size: {file_size_mb_acc:.2f} MB\")\n",
    "\n",
    "with rasterio.open(output_tif_acc) as tif_check_acc:\n",
    "    print(f\"üìå CRS: {tif_check_acc.crs}\")\n",
    "    print(f\"üß≠ Bounds: {tif_check_acc.bounds}\")\n",
    "    print(f\"üì¶ Data type: {tif_check_acc.dtypes[0]}\")\n",
    "    print(f\"üßÆ NoData value: {tif_check_acc.nodata}\")\n",
    "\n",
    "# üî• Clean up memory (ACC)\n",
    "del data_acc, transform_acc, out_meta_acc, window_acc, tif_check_acc, src_acc, out_src_acc\n",
    "gc.collect()\n",
    "print(\"‚úÖ Memory cleaned up (ACC).\")\n",
    "\n",
    "\n",
    "# === DIR ===\n",
    "input_tif_dir  = \"../../data/HydroSHEDS/as_dir_3s.tif\"\n",
    "output_tif_dir = \"../../data/HydroSHEDS/as_dir_Bhutan_and_buffer.tif\"\n",
    "\n",
    "with rasterio.open(input_tif_dir) as src_dir:\n",
    "    print(f\"üì¶ Number of bands in TIFF: {src_dir.count}\")\n",
    "    if src_dir.count != 1:\n",
    "        raise ValueError(\"‚ùå Expected only one band in the DIR file.\")\n",
    "\n",
    "    window_dir = from_bounds(min_lon, min_lat, max_lon, max_lat, transform=src_dir.transform)\n",
    "\n",
    "    data_dir = src_dir.read(1, window=window_dir)\n",
    "    transform_dir = src_dir.window_transform(window_dir)\n",
    "\n",
    "    out_meta_dir = src_dir.meta.copy()\n",
    "    out_meta_dir.update({\n",
    "        \"height\": window_dir.height,\n",
    "        \"width\": window_dir.width,\n",
    "        \"transform\": transform_dir\n",
    "    })\n",
    "\n",
    "    with rasterio.open(output_tif_dir, \"w\", **out_meta_dir) as out_src_dir:\n",
    "        out_src_dir.write(data_dir, 1)\n",
    "\n",
    "print(f\"‚úÖ Saved: {output_tif_dir}\")\n",
    "print(f\"üìê Size (width x height): {window_dir.width} x {window_dir.height}\")\n",
    "\n",
    "file_size_mb_dir = os.path.getsize(output_tif_dir) / (1024 * 1024)\n",
    "print(f\"üíæ File size: {file_size_mb_dir:.2f} MB\")\n",
    "\n",
    "with rasterio.open(output_tif_dir) as tif_check_dir:\n",
    "    print(f\"üìå CRS: {tif_check_dir.crs}\")\n",
    "    print(f\"üß≠ Bounds: {tif_check_dir.bounds}\")\n",
    "    print(f\"üì¶ Data type: {tif_check_dir.dtypes[0]}\")\n",
    "    print(f\"üßÆ NoData value: {tif_check_dir.nodata}\")\n",
    "\n",
    "# üî• Clean up memory (DIR)\n",
    "del data_dir, transform_dir, out_meta_dir, window_dir, tif_check_dir, src_dir, out_src_dir\n",
    "gc.collect()\n",
    "print(\"‚úÖ Memory cleaned up (DIR).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0596a9ea",
   "metadata": {},
   "source": [
    "## 2. Generate catchments (basins) from DIR\n",
    "Note: ESRI-D8 flow direction: a raster layer of flow directions using ESRI‚Äôs D8 scheme. Each pixel stores a code for the direction water flows to:\n",
    "1 = E, 2 = SE, 4 = S, 8 = SW, 16 = W, 32 = NW, 64 = N, 128 = NE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ac218ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installing pyogrio ...\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyogrio\n",
      "  Downloading pyogrio-0.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from pyogrio) (2019.11.28)\n",
      "Requirement already satisfied: numpy in /home/merlin/.local/lib/python3.8/site-packages (from pyogrio) (1.24.4)\n",
      "Requirement already satisfied: packaging in /home/merlin/.local/lib/python3.8/site-packages (from pyogrio) (25.0)\n",
      "Downloading pyogrio-0.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Error parsing dependencies of distro-info: Invalid version: '0.23ubuntu1'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of python-debian: Invalid version: '0.1.36ubuntu1'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: pyogrio\n",
      "Successfully installed pyogrio-0.9.0\n",
      "Using ACC threshold = 10000 cells\n",
      "‚úÖ DIR/ACC aligned: 7800 x 5400 | CRS=EPSG:4326\n",
      "./whitebox_tools --run=\"ExtractStreams\" --wd=\"/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out\" --flow_accum='/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/as_acc_Bhutan_and_buffer.tif' --output='/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/streams.tif' --threshold='10000' -v --compress_rasters=False\n",
      "\n",
      "*****************************\n",
      "* Welcome to ExtractStreams *\n",
      "* Powered by WhiteboxTools  *\n",
      "* www.whiteboxgeo.com       *\n",
      "*****************************\n",
      "Reading data...\n",
      "Progress: 0%\n",
      "Progress: 1%\n",
      "Progress: 2%\n",
      "Progress: 3%\n",
      "Progress: 4%\n",
      "Progress: 5%\n",
      "Progress: 6%\n",
      "Progress: 7%\n",
      "Progress: 8%\n",
      "Progress: 9%\n",
      "Progress: 10%\n",
      "Progress: 11%\n",
      "Progress: 12%\n",
      "Progress: 13%\n",
      "Progress: 14%\n",
      "Progress: 15%\n",
      "Progress: 16%\n",
      "Progress: 17%\n",
      "Progress: 18%\n",
      "Progress: 19%\n",
      "Progress: 20%\n",
      "Progress: 21%\n",
      "Progress: 22%\n",
      "Progress: 23%\n",
      "Progress: 24%\n",
      "Progress: 25%\n",
      "Progress: 26%\n",
      "Progress: 27%\n",
      "Progress: 28%\n",
      "Progress: 29%\n",
      "Progress: 30%\n",
      "Progress: 31%\n",
      "Progress: 32%\n",
      "Progress: 33%\n",
      "Progress: 34%\n",
      "Progress: 35%\n",
      "Progress: 36%\n",
      "Progress: 37%\n",
      "Progress: 38%\n",
      "Progress: 39%\n",
      "Progress: 40%\n",
      "Progress: 41%\n",
      "Progress: 42%\n",
      "Progress: 43%\n",
      "Progress: 44%\n",
      "Progress: 45%\n",
      "Progress: 46%\n",
      "Progress: 47%\n",
      "Progress: 48%\n",
      "Progress: 49%\n",
      "Progress: 50%\n",
      "Progress: 51%\n",
      "Progress: 52%\n",
      "Progress: 53%\n",
      "Progress: 54%\n",
      "Progress: 55%\n",
      "Progress: 56%\n",
      "Progress: 57%\n",
      "Progress: 58%\n",
      "Progress: 59%\n",
      "Progress: 60%\n",
      "Progress: 61%\n",
      "Progress: 62%\n",
      "Progress: 63%\n",
      "Progress: 64%\n",
      "Progress: 65%\n",
      "Progress: 66%\n",
      "Progress: 67%\n",
      "Progress: 68%\n",
      "Progress: 69%\n",
      "Progress: 70%\n",
      "Progress: 71%\n",
      "Progress: 72%\n",
      "Progress: 73%\n",
      "Progress: 74%\n",
      "Progress: 75%\n",
      "Progress: 76%\n",
      "Progress: 77%\n",
      "Progress: 78%\n",
      "Progress: 79%\n",
      "Progress: 80%\n",
      "Progress: 81%\n",
      "Progress: 82%\n",
      "Progress: 83%\n",
      "Progress: 84%\n",
      "Progress: 85%\n",
      "Progress: 86%\n",
      "Progress: 87%\n",
      "Progress: 88%\n",
      "Progress: 89%\n",
      "Progress: 90%\n",
      "Progress: 91%\n",
      "Progress: 92%\n",
      "Progress: 93%\n",
      "Progress: 94%\n",
      "Progress: 95%\n",
      "Progress: 96%\n",
      "Progress: 97%\n",
      "Progress: 98%\n",
      "Progress: 99%\n",
      "Progress: 100%\n",
      "Saving data...\n",
      "Output file written\n",
      "Elapsed Time (excluding I/O): 0.274s\n",
      "‚úÖ Streams: 0 ‚Üí /home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/streams.tif\n",
      "üîé Candidate boundary outlets (raw): 8440\n",
      "‚úÖ Clustered outlets (one per mouth): 1761\n",
      "‚úÖ Pour-point raster (clustered): /home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/auto_pour_points_clustered.tif\n",
      "./whitebox_tools --run=\"Watershed\" --wd=\"/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out\" --d8_pntr='/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/as_dir_Bhutan_and_buffer.tif' --pour_pts='/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/auto_pour_points_clustered.tif' --output='/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_by_outlets_clustered.tif' --esri_pntr -v --compress_rasters=False\n",
      "\n",
      "****************************\n",
      "* Welcome to Watershed     *\n",
      "* Powered by WhiteboxTools *\n",
      "* www.whiteboxgeo.com      *\n",
      "****************************\n",
      "Reading data...\n",
      "Initializing: 0%\n",
      "Initializing: 1%\n",
      "Initializing: 2%\n",
      "Initializing: 3%\n",
      "Initializing: 4%\n",
      "Initializing: 5%\n",
      "Initializing: 6%\n",
      "Initializing: 7%\n",
      "Initializing: 8%\n",
      "Initializing: 9%\n",
      "Initializing: 10%\n",
      "Initializing: 11%\n",
      "Initializing: 12%\n",
      "Initializing: 13%\n",
      "Initializing: 14%\n",
      "Initializing: 15%\n",
      "Initializing: 16%\n",
      "Initializing: 17%\n",
      "Initializing: 18%\n",
      "Initializing: 19%\n",
      "Initializing: 20%\n",
      "Initializing: 21%\n",
      "Initializing: 22%\n",
      "Initializing: 23%\n",
      "Initializing: 24%\n",
      "Initializing: 25%\n",
      "Initializing: 26%\n",
      "Initializing: 27%\n",
      "Initializing: 28%\n",
      "Initializing: 29%\n",
      "Initializing: 30%\n",
      "Initializing: 31%\n",
      "Initializing: 32%\n",
      "Initializing: 33%\n",
      "Initializing: 34%\n",
      "Initializing: 35%\n",
      "Initializing: 36%\n",
      "Initializing: 37%\n",
      "Initializing: 38%\n",
      "Initializing: 39%\n",
      "Initializing: 40%\n",
      "Initializing: 41%\n",
      "Initializing: 42%\n",
      "Initializing: 43%\n",
      "Initializing: 44%\n",
      "Initializing: 45%\n",
      "Initializing: 46%\n",
      "Initializing: 47%\n",
      "Initializing: 48%\n",
      "Initializing: 49%\n",
      "Initializing: 50%\n",
      "Initializing: 51%\n",
      "Initializing: 52%\n",
      "Initializing: 53%\n",
      "Initializing: 54%\n",
      "Initializing: 55%\n",
      "Initializing: 56%\n",
      "Initializing: 57%\n",
      "Initializing: 58%\n",
      "Initializing: 59%\n",
      "Initializing: 60%\n",
      "Initializing: 61%\n",
      "Initializing: 62%\n",
      "Initializing: 63%\n",
      "Initializing: 64%\n",
      "Initializing: 65%\n",
      "Initializing: 66%\n",
      "Initializing: 67%\n",
      "Initializing: 68%\n",
      "Initializing: 69%\n",
      "Initializing: 70%\n",
      "Initializing: 71%\n",
      "Initializing: 72%\n",
      "Initializing: 73%\n",
      "Initializing: 74%\n",
      "Initializing: 75%\n",
      "Initializing: 76%\n",
      "Initializing: 77%\n",
      "Initializing: 78%\n",
      "Initializing: 79%\n",
      "Initializing: 80%\n",
      "Initializing: 81%\n",
      "Initializing: 82%\n",
      "Initializing: 83%\n",
      "Initializing: 84%\n",
      "Initializing: 85%\n",
      "Initializing: 86%\n",
      "Initializing: 87%\n",
      "Initializing: 88%\n",
      "Initializing: 89%\n",
      "Initializing: 90%\n",
      "Initializing: 91%\n",
      "Initializing: 92%\n",
      "Initializing: 93%\n",
      "Initializing: 94%\n",
      "Initializing: 95%\n",
      "Initializing: 96%\n",
      "Initializing: 97%\n",
      "Initializing: 98%\n",
      "Initializing: 99%\n",
      "Initializing: 100%\n",
      "Progress: 0%\n",
      "Progress: 1%\n",
      "Progress: 2%\n",
      "Progress: 3%\n",
      "Progress: 4%\n",
      "Progress: 5%\n",
      "Progress: 6%\n",
      "Progress: 7%\n",
      "Progress: 8%\n",
      "Progress: 9%\n",
      "Progress: 10%\n",
      "Progress: 11%\n",
      "Progress: 12%\n",
      "Progress: 13%\n",
      "Progress: 14%\n",
      "Progress: 15%\n",
      "Progress: 16%\n",
      "Progress: 17%\n",
      "Progress: 18%\n",
      "Progress: 19%\n",
      "Progress: 20%\n",
      "Progress: 21%\n",
      "Progress: 22%\n",
      "Progress: 23%\n",
      "Progress: 24%\n",
      "Progress: 25%\n",
      "Progress: 26%\n",
      "Progress: 27%\n",
      "Progress: 28%\n",
      "Progress: 29%\n",
      "Progress: 30%\n",
      "Progress: 31%\n",
      "Progress: 32%\n",
      "Progress: 33%\n",
      "Progress: 34%\n",
      "Progress: 35%\n",
      "Progress: 36%\n",
      "Progress: 37%\n",
      "Progress: 38%\n",
      "Progress: 39%\n",
      "Progress: 40%\n",
      "Progress: 41%\n",
      "Progress: 42%\n",
      "Progress: 43%\n",
      "Progress: 44%\n",
      "Progress: 45%\n",
      "Progress: 46%\n",
      "Progress: 47%\n",
      "Progress: 48%\n",
      "Progress: 49%\n",
      "Progress: 50%\n",
      "Progress: 51%\n",
      "Progress: 52%\n",
      "Progress: 53%\n",
      "Progress: 54%\n",
      "Progress: 55%\n",
      "Progress: 56%\n",
      "Progress: 57%\n",
      "Progress: 58%\n",
      "Progress: 59%\n",
      "Progress: 60%\n",
      "Progress: 61%\n",
      "Progress: 62%\n",
      "Progress: 63%\n",
      "Progress: 64%\n",
      "Progress: 65%\n",
      "Progress: 66%\n",
      "Progress: 67%\n",
      "Progress: 68%\n",
      "Progress: 69%\n",
      "Progress: 70%\n",
      "Progress: 71%\n",
      "Progress: 72%\n",
      "Progress: 73%\n",
      "Progress: 74%\n",
      "Progress: 75%\n",
      "Progress: 76%\n",
      "Progress: 77%\n",
      "Progress: 78%\n",
      "Progress: 79%\n",
      "Progress: 80%\n",
      "Progress: 81%\n",
      "Progress: 82%\n",
      "Progress: 83%\n",
      "Progress: 84%\n",
      "Progress: 85%\n",
      "Progress: 86%\n",
      "Progress: 87%\n",
      "Progress: 88%\n",
      "Progress: 89%\n",
      "Progress: 90%\n",
      "Progress: 91%\n",
      "Progress: 92%\n",
      "Progress: 93%\n",
      "Progress: 94%\n",
      "Progress: 95%\n",
      "Progress: 96%\n",
      "Progress: 97%\n",
      "Progress: 98%\n",
      "Progress: 99%\n",
      "Progress: 100%\n",
      "Saving data...\n",
      "Output file written\n",
      "Elapsed Time (excluding I/O): 2.518s\n",
      "‚úÖ Watersheds by clustered outlets: 0 ‚Üí /home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_by_outlets_clustered.tif\n",
      "./whitebox_tools --run=\"RasterToVectorPolygons\" --wd=\"/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out\" --input='/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_by_outlets_clustered.tif' --output='/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_by_outlets_clustered.shp' -v --compress_rasters=False\n",
      "\n",
      "*************************************\n",
      "* Welcome to RasterToVectorPolygons *\n",
      "* Powered by WhiteboxTools          *\n",
      "* www.whiteboxgeo.com               *\n",
      "*************************************\n",
      "Reading data...\n",
      "Clumping polygons: 0%\n",
      "Clumping polygons: 1%\n",
      "Clumping polygons: 2%\n",
      "Clumping polygons: 3%\n",
      "Clumping polygons: 4%\n",
      "Clumping polygons: 5%\n",
      "Clumping polygons: 6%\n",
      "Clumping polygons: 7%\n",
      "Clumping polygons: 8%\n",
      "Clumping polygons: 9%\n",
      "Clumping polygons: 10%\n",
      "Clumping polygons: 11%\n",
      "Clumping polygons: 12%\n",
      "Clumping polygons: 13%\n",
      "Clumping polygons: 14%\n",
      "Clumping polygons: 15%\n",
      "Clumping polygons: 16%\n",
      "Clumping polygons: 17%\n",
      "Clumping polygons: 18%\n",
      "Clumping polygons: 19%\n",
      "Clumping polygons: 20%\n",
      "Clumping polygons: 21%\n",
      "Clumping polygons: 22%\n",
      "Clumping polygons: 23%\n",
      "Clumping polygons: 24%\n",
      "Clumping polygons: 25%\n",
      "Clumping polygons: 26%\n",
      "Clumping polygons: 27%\n",
      "Clumping polygons: 28%\n",
      "Clumping polygons: 29%\n",
      "Clumping polygons: 30%\n",
      "Clumping polygons: 31%\n",
      "Clumping polygons: 32%\n",
      "Clumping polygons: 33%\n",
      "Clumping polygons: 34%\n",
      "Clumping polygons: 35%\n",
      "Clumping polygons: 36%\n",
      "Clumping polygons: 37%\n",
      "Clumping polygons: 38%\n",
      "Clumping polygons: 39%\n",
      "Clumping polygons: 40%\n",
      "Clumping polygons: 41%\n",
      "Clumping polygons: 42%\n",
      "Clumping polygons: 43%\n",
      "Clumping polygons: 44%\n",
      "Clumping polygons: 45%\n",
      "Clumping polygons: 46%\n",
      "Clumping polygons: 47%\n",
      "Clumping polygons: 48%\n",
      "Clumping polygons: 49%\n",
      "Clumping polygons: 50%\n",
      "Clumping polygons: 51%\n",
      "Clumping polygons: 52%\n",
      "Clumping polygons: 53%\n",
      "Clumping polygons: 54%\n",
      "Clumping polygons: 55%\n",
      "Clumping polygons: 56%\n",
      "Clumping polygons: 57%\n",
      "Clumping polygons: 58%\n",
      "Clumping polygons: 59%\n",
      "Clumping polygons: 60%\n",
      "Clumping polygons: 61%\n",
      "Clumping polygons: 62%\n",
      "Clumping polygons: 63%\n",
      "Clumping polygons: 64%\n",
      "Clumping polygons: 65%\n",
      "Clumping polygons: 66%\n",
      "Clumping polygons: 67%\n",
      "Clumping polygons: 68%\n",
      "Clumping polygons: 69%\n",
      "Clumping polygons: 70%\n",
      "Clumping polygons: 71%\n",
      "Clumping polygons: 72%\n",
      "Clumping polygons: 73%\n",
      "Clumping polygons: 74%\n",
      "Clumping polygons: 75%\n",
      "Clumping polygons: 76%\n",
      "Clumping polygons: 77%\n",
      "Clumping polygons: 78%\n",
      "Clumping polygons: 79%\n",
      "Clumping polygons: 80%\n",
      "Clumping polygons: 81%\n",
      "Clumping polygons: 82%\n",
      "Clumping polygons: 83%\n",
      "Clumping polygons: 84%\n",
      "Clumping polygons: 85%\n",
      "Clumping polygons: 86%\n",
      "Clumping polygons: 87%\n",
      "Clumping polygons: 88%\n",
      "Clumping polygons: 89%\n",
      "Clumping polygons: 90%\n",
      "Clumping polygons: 91%\n",
      "Clumping polygons: 92%\n",
      "Clumping polygons: 93%\n",
      "Clumping polygons: 94%\n",
      "Clumping polygons: 95%\n",
      "Clumping polygons: 96%\n",
      "Clumping polygons: 97%\n",
      "Clumping polygons: 98%\n",
      "Clumping polygons: 99%\n",
      "Clumping polygons: 100%\n",
      "Finding edges: 0%\n",
      "Finding edges: 1%\n",
      "Finding edges: 2%\n",
      "Finding edges: 3%\n",
      "Finding edges: 4%\n",
      "Finding edges: 5%\n",
      "Finding edges: 6%\n",
      "Finding edges: 7%\n",
      "Finding edges: 8%\n",
      "Finding edges: 9%\n",
      "Finding edges: 10%\n",
      "Finding edges: 11%\n",
      "Finding edges: 12%\n",
      "Finding edges: 13%\n",
      "Finding edges: 14%\n",
      "Finding edges: 15%\n",
      "Finding edges: 16%\n",
      "Finding edges: 17%\n",
      "Finding edges: 18%\n",
      "Finding edges: 19%\n",
      "Finding edges: 20%\n",
      "Finding edges: 21%\n",
      "Finding edges: 22%\n",
      "Finding edges: 23%\n",
      "Finding edges: 24%\n",
      "Finding edges: 25%\n",
      "Finding edges: 26%\n",
      "Finding edges: 27%\n",
      "Finding edges: 28%\n",
      "Finding edges: 29%\n",
      "Finding edges: 30%\n",
      "Finding edges: 31%\n",
      "Finding edges: 32%\n",
      "Finding edges: 33%\n",
      "Finding edges: 34%\n",
      "Finding edges: 35%\n",
      "Finding edges: 36%\n",
      "Finding edges: 37%\n",
      "Finding edges: 38%\n",
      "Finding edges: 39%\n",
      "Finding edges: 40%\n",
      "Finding edges: 41%\n",
      "Finding edges: 42%\n",
      "Finding edges: 43%\n",
      "Finding edges: 44%\n",
      "Finding edges: 45%\n",
      "Finding edges: 46%\n",
      "Finding edges: 47%\n",
      "Finding edges: 48%\n",
      "Finding edges: 49%\n",
      "Finding edges: 50%\n",
      "Finding edges: 51%\n",
      "Finding edges: 52%\n",
      "Finding edges: 53%\n",
      "Finding edges: 54%\n",
      "Finding edges: 55%\n",
      "Finding edges: 56%\n",
      "Finding edges: 57%\n",
      "Finding edges: 58%\n",
      "Finding edges: 59%\n",
      "Finding edges: 60%\n",
      "Finding edges: 61%\n",
      "Finding edges: 62%\n",
      "Finding edges: 63%\n",
      "Finding edges: 64%\n",
      "Finding edges: 65%\n",
      "Finding edges: 66%\n",
      "Finding edges: 67%\n",
      "Finding edges: 68%\n",
      "Finding edges: 69%\n",
      "Finding edges: 70%\n",
      "Finding edges: 71%\n",
      "Finding edges: 72%\n",
      "Finding edges: 73%\n",
      "Finding edges: 74%\n",
      "Finding edges: 75%\n",
      "Finding edges: 76%\n",
      "Finding edges: 77%\n",
      "Finding edges: 78%\n",
      "Finding edges: 79%\n",
      "Finding edges: 80%\n",
      "Finding edges: 81%\n",
      "Finding edges: 82%\n",
      "Finding edges: 83%\n",
      "Finding edges: 84%\n",
      "Finding edges: 85%\n",
      "Finding edges: 86%\n",
      "Finding edges: 87%\n",
      "Finding edges: 88%\n",
      "Finding edges: 89%\n",
      "Finding edges: 90%\n",
      "Finding edges: 91%\n",
      "Finding edges: 92%\n",
      "Finding edges: 93%\n",
      "Finding edges: 94%\n",
      "Finding edges: 95%\n",
      "Finding edges: 96%\n",
      "Finding edges: 97%\n",
      "Finding edges: 98%\n",
      "Finding edges: 99%\n",
      "Finding edges: 100%\n",
      "Tracing polygons: 0%\n",
      "Tracing polygons: 1%\n",
      "Tracing polygons: 2%\n",
      "Tracing polygons: 3%\n",
      "Tracing polygons: 4%\n",
      "Tracing polygons: 5%\n",
      "Tracing polygons: 6%\n",
      "Tracing polygons: 7%\n",
      "Tracing polygons: 8%\n",
      "Tracing polygons: 9%\n",
      "Tracing polygons: 10%\n",
      "Tracing polygons: 11%\n",
      "Tracing polygons: 12%\n",
      "Tracing polygons: 13%\n",
      "Tracing polygons: 14%\n",
      "Tracing polygons: 15%\n",
      "Tracing polygons: 16%\n",
      "Tracing polygons: 17%\n",
      "Tracing polygons: 18%\n",
      "Tracing polygons: 19%\n",
      "Tracing polygons: 20%\n",
      "Tracing polygons: 21%\n",
      "Tracing polygons: 22%\n",
      "Tracing polygons: 23%\n",
      "Tracing polygons: 24%\n",
      "Tracing polygons: 25%\n",
      "Tracing polygons: 26%\n",
      "Tracing polygons: 27%\n",
      "Tracing polygons: 28%\n",
      "Tracing polygons: 29%\n",
      "Tracing polygons: 30%\n",
      "Tracing polygons: 31%\n",
      "Tracing polygons: 32%\n",
      "Tracing polygons: 33%\n",
      "Tracing polygons: 34%\n",
      "Tracing polygons: 35%\n",
      "Tracing polygons: 36%\n",
      "Tracing polygons: 37%\n",
      "Tracing polygons: 38%\n",
      "Tracing polygons: 39%\n",
      "Tracing polygons: 40%\n",
      "Tracing polygons: 41%\n",
      "Tracing polygons: 42%\n",
      "Tracing polygons: 43%\n",
      "Tracing polygons: 44%\n",
      "Tracing polygons: 45%\n",
      "Tracing polygons: 46%\n",
      "Tracing polygons: 47%\n",
      "Tracing polygons: 48%\n",
      "Tracing polygons: 49%\n",
      "Tracing polygons: 50%\n",
      "Tracing polygons: 51%\n",
      "Tracing polygons: 52%\n",
      "Tracing polygons: 53%\n",
      "Tracing polygons: 54%\n",
      "Tracing polygons: 55%\n",
      "Tracing polygons: 56%\n",
      "Tracing polygons: 57%\n",
      "Tracing polygons: 58%\n",
      "Tracing polygons: 59%\n",
      "Tracing polygons: 60%\n",
      "Tracing polygons: 61%\n",
      "Tracing polygons: 62%\n",
      "Tracing polygons: 63%\n",
      "Tracing polygons: 64%\n",
      "Tracing polygons: 65%\n",
      "Tracing polygons: 66%\n",
      "Tracing polygons: 67%\n",
      "Tracing polygons: 68%\n",
      "Tracing polygons: 69%\n",
      "Tracing polygons: 70%\n",
      "Tracing polygons: 71%\n",
      "Tracing polygons: 72%\n",
      "Tracing polygons: 73%\n",
      "Tracing polygons: 74%\n",
      "Tracing polygons: 75%\n",
      "Tracing polygons: 76%\n",
      "Tracing polygons: 77%\n",
      "Tracing polygons: 78%\n",
      "Tracing polygons: 79%\n",
      "Tracing polygons: 80%\n",
      "Tracing polygons: 81%\n",
      "Tracing polygons: 82%\n",
      "Tracing polygons: 83%\n",
      "Tracing polygons: 84%\n",
      "Tracing polygons: 85%\n",
      "Tracing polygons: 86%\n",
      "Tracing polygons: 87%\n",
      "Tracing polygons: 88%\n",
      "Tracing polygons: 89%\n",
      "Tracing polygons: 90%\n",
      "Tracing polygons: 91%\n",
      "Tracing polygons: 92%\n",
      "Tracing polygons: 93%\n",
      "Tracing polygons: 94%\n",
      "Tracing polygons: 95%\n",
      "Tracing polygons: 96%\n",
      "Tracing polygons: 97%\n",
      "Tracing polygons: 98%\n",
      "Tracing polygons: 99%\n",
      "Tracing polygons: 100%\n",
      "Creating geometries: 0%\n",
      "Creating geometries: 1%\n",
      "Creating geometries: 2%\n",
      "Creating geometries: 3%\n",
      "Creating geometries: 4%\n",
      "Creating geometries: 5%\n",
      "Creating geometries: 6%\n",
      "Creating geometries: 7%\n",
      "Creating geometries: 8%\n",
      "Creating geometries: 9%\n",
      "Creating geometries: 10%\n",
      "Creating geometries: 11%\n",
      "Creating geometries: 12%\n",
      "Creating geometries: 13%\n",
      "Creating geometries: 14%\n",
      "Creating geometries: 15%\n",
      "Creating geometries: 16%\n",
      "Creating geometries: 17%\n",
      "Creating geometries: 18%\n",
      "Creating geometries: 19%\n",
      "Creating geometries: 20%\n",
      "Creating geometries: 21%\n",
      "Creating geometries: 22%\n",
      "Creating geometries: 23%\n",
      "Creating geometries: 24%\n",
      "Creating geometries: 25%\n",
      "Creating geometries: 26%\n",
      "Creating geometries: 27%\n",
      "Creating geometries: 28%\n",
      "Creating geometries: 29%\n",
      "Creating geometries: 30%\n",
      "Creating geometries: 31%\n",
      "Creating geometries: 32%\n",
      "Creating geometries: 33%\n",
      "Creating geometries: 34%\n",
      "Creating geometries: 35%\n",
      "Creating geometries: 36%\n",
      "Creating geometries: 37%\n",
      "Creating geometries: 38%\n",
      "Creating geometries: 39%\n",
      "Creating geometries: 40%\n",
      "Creating geometries: 41%\n",
      "Creating geometries: 42%\n",
      "Creating geometries: 43%\n",
      "Creating geometries: 44%\n",
      "Creating geometries: 45%\n",
      "Creating geometries: 46%\n",
      "Creating geometries: 47%\n",
      "Creating geometries: 48%\n",
      "Creating geometries: 49%\n",
      "Creating geometries: 50%\n",
      "Creating geometries: 51%\n",
      "Creating geometries: 52%\n",
      "Creating geometries: 53%\n",
      "Creating geometries: 54%\n",
      "Creating geometries: 55%\n",
      "Creating geometries: 56%\n",
      "Creating geometries: 57%\n",
      "Creating geometries: 58%\n",
      "Creating geometries: 59%\n",
      "Creating geometries: 60%\n",
      "Creating geometries: 61%\n",
      "Creating geometries: 62%\n",
      "Creating geometries: 63%\n",
      "Creating geometries: 64%\n",
      "Creating geometries: 65%\n",
      "Creating geometries: 66%\n",
      "Creating geometries: 67%\n",
      "Creating geometries: 68%\n",
      "Creating geometries: 69%\n",
      "Creating geometries: 70%\n",
      "Creating geometries: 71%\n",
      "Creating geometries: 72%\n",
      "Creating geometries: 73%\n",
      "Creating geometries: 74%\n",
      "Creating geometries: 75%\n",
      "Creating geometries: 76%\n",
      "Creating geometries: 77%\n",
      "Creating geometries: 78%\n",
      "Creating geometries: 79%\n",
      "Creating geometries: 80%\n",
      "Creating geometries: 81%\n",
      "Creating geometries: 82%\n",
      "Creating geometries: 83%\n",
      "Creating geometries: 84%\n",
      "Creating geometries: 85%\n",
      "Creating geometries: 86%\n",
      "Creating geometries: 87%\n",
      "Creating geometries: 88%\n",
      "Creating geometries: 89%\n",
      "Creating geometries: 90%\n",
      "Creating geometries: 91%\n",
      "Creating geometries: 92%\n",
      "Creating geometries: 93%\n",
      "Creating geometries: 94%\n",
      "Creating geometries: 95%\n",
      "Creating geometries: 96%\n",
      "Creating geometries: 97%\n",
      "Creating geometries: 98%\n",
      "Creating geometries: 99%\n",
      "Creating geometries: 100%\n",
      "Saving data...\n",
      "Output file written\n",
      "Elapsed Time (excluding I/O): 13.34s\n",
      "‚úÖ Polygons (SHP): 0 ‚Üí /home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_by_outlets_clustered.shp\n",
      "‚úÖ GeoPackage written (pyogrio): /home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_by_outlets_clustered.gpkg\n",
      "Layers: [['watersheds' 'MultiPolygon']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/merlin/.local/lib/python3.8/site-packages/pyogrio/raw.py:196: RuntimeWarning: /home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_by_outlets_clustered.shp contains polygon(s) with rings with invalid winding order. Autocorrecting them, but that shapefile should be corrected using ogr2ogr for example.\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßÆ Unique watersheds (clustered): 1761\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# === Install (into THIS kernel) + Build clustered watersheds @ ACC threshold = 10,000 ===\n",
    "# - Installs: pyogrio (for GPKG I/O), geopandas (optional)\n",
    "# - Streams from ACC (threshold = 10,000)\n",
    "# - Boundary outlet candidates -> 8-connected clusters -> pick max-ACC per cluster\n",
    "# - Watershed per selected outlet (ESRI-D8), polygonize to SHP, write GPKG via pyogrio\n",
    "\n",
    "import sys, subprocess, os, gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "# 0) Install libs into THIS kernel (idempotent)\n",
    "def ensure_package(name):\n",
    "    try:\n",
    "        __import__(name)\n",
    "        return\n",
    "    except ImportError:\n",
    "        print(f\"üì¶ Installing {name} ...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", name])\n",
    "        __import__(name)\n",
    "\n",
    "for pkg in [\"pyogrio\", \"geopandas\"]:\n",
    "    ensure_package(pkg)\n",
    "\n",
    "import pyogrio  # now available\n",
    "\n",
    "# 1) Py3.8 shim so whitebox works on Python < 3.9\n",
    "if sys.version_info < (3, 9):\n",
    "    import importlib.resources as ir\n",
    "    try:\n",
    "        import importlib_resources\n",
    "        if not hasattr(ir, \"files\"):\n",
    "            ir.files = importlib_resources.files\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "import whitebox\n",
    "wbt = whitebox.WhiteboxTools()\n",
    "\n",
    "# 2) Parameters\n",
    "THRESHOLD_CELLS = 10_000  # ACC >= 10k -> stream (~81 km¬≤ if 0.0081 km¬≤/pixel)\n",
    "print(f\"Using ACC threshold = {THRESHOLD_CELLS} cells\")\n",
    "\n",
    "# 3) Paths (absolute)\n",
    "root = Path(\"../../data/HydroSHEDS\").resolve()\n",
    "dir_tif = (root / \"as_dir_Bhutan_and_buffer.tif\").resolve()\n",
    "acc_tif = (root / \"as_acc_Bhutan_and_buffer.tif\").resolve()\n",
    "out_dir = (root / \"bt_out\").resolve()\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "streams_tif = out_dir / \"streams.tif\"\n",
    "pp_rast     = out_dir / \"auto_pour_points_clustered.tif\"\n",
    "ws_tif      = out_dir / \"watersheds_by_outlets_clustered.tif\"\n",
    "ws_shp      = out_dir / \"watersheds_by_outlets_clustered.shp\"\n",
    "ws_gpkg     = out_dir / \"watersheds_by_outlets_clustered.gpkg\"\n",
    "\n",
    "def safe_remove(p: Path):\n",
    "    try:\n",
    "        if p.exists():\n",
    "            p.unlink()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not remove {p}: {e}\")\n",
    "\n",
    "def cleanup_shapefile(stem: Path):\n",
    "    base = stem.with_suffix(\"\")\n",
    "    for ext in (\".shp\", \".shx\", \".dbf\", \".prj\", \".cpg\", \".qmd\"):\n",
    "        safe_remove(base.with_suffix(ext))\n",
    "\n",
    "# clean old outputs\n",
    "for p in [streams_tif, pp_rast, ws_tif, ws_gpkg]:\n",
    "    safe_remove(p)\n",
    "cleanup_shapefile(ws_shp)\n",
    "\n",
    "# 4) Input checks & alignment\n",
    "assert dir_tif.exists(), f\"Missing DIR: {dir_tif}\"\n",
    "assert acc_tif.exists(), f\"Missing ACC: {acc_tif}\"\n",
    "with rasterio.open(dir_tif) as rD, rasterio.open(acc_tif) as rA:\n",
    "    assert rD.crs == rA.crs, \"DIR and ACC CRS differ\"\n",
    "    assert rD.transform == rA.transform, \"DIR and ACC grids not aligned\"\n",
    "    assert (rD.width, rD.height) == (rA.width, rA.height), \"DIR and ACC size mismatch\"\n",
    "    H, W = rD.height, rD.width\n",
    "    profile = rD.profile\n",
    "print(f\"‚úÖ DIR/ACC aligned: {W} x {H} | CRS={profile['crs']}\")\n",
    "\n",
    "wbt.work_dir = str(out_dir)\n",
    "\n",
    "# 5) Streams from ACC\n",
    "ok_s = wbt.extract_streams(flow_accum=str(acc_tif), output=str(streams_tif), threshold=THRESHOLD_CELLS)\n",
    "print(\"‚úÖ Streams:\", ok_s, \"‚Üí\", streams_tif)\n",
    "\n",
    "# 6) Boundary outlet candidates (stream on outer border + D8 points outside)\n",
    "with rasterio.open(dir_tif) as r_dir, rasterio.open(streams_tif) as r_str:\n",
    "    dir_arr = r_dir.read(1)\n",
    "    str_arr = r_str.read(1).astype(bool)\n",
    "\n",
    "code2offset = {1:(0,1), 2:(1,1), 4:(1,0), 8:(1,-1), 16:(0,-1), 32:(-1,-1), 64:(-1,0), 128:(-1,1)}\n",
    "\n",
    "cand_coords = []\n",
    "# top/bottom rows\n",
    "for c in range(W):\n",
    "    for r in (0, H-1):\n",
    "        if str_arr[r, c]:\n",
    "            d = int(dir_arr[r, c])\n",
    "            if d in code2offset:\n",
    "                dr, dc = code2offset[d]\n",
    "                nr, nc = r + dr, c + dc\n",
    "                if nr < 0 or nr >= H or nc < 0 or nc >= W:\n",
    "                    cand_coords.append((r, c))\n",
    "# left/right cols (skip corners to avoid dupes)\n",
    "for r in range(1, H-1):\n",
    "    for c in (0, W-1):\n",
    "        if str_arr[r, c]:\n",
    "            d = int(dir_arr[r, c])\n",
    "            if d in code2offset:\n",
    "                dr, dc = code2offset[d]\n",
    "                nr, nc = r + dr, c + dc\n",
    "                if nr < 0 or nr >= H or nc < 0 or nc >= W:\n",
    "                    cand_coords.append((r, c))\n",
    "\n",
    "cand_coords = list(dict.fromkeys(cand_coords))\n",
    "print(f\"üîé Candidate boundary outlets (raw): {len(cand_coords)}\")\n",
    "\n",
    "# 7) Cluster candidates (8-connectivity) and pick max-ACC per cluster\n",
    "class DSU:\n",
    "    def __init__(self, n):\n",
    "        self.p = list(range(n)); self.r = [0]*n\n",
    "    def find(self, x):\n",
    "        while self.p[x] != x:\n",
    "            self.p[x] = self.p[self.p[x]]\n",
    "            x = self.p[x]\n",
    "        return x\n",
    "    def union(self, a, b):\n",
    "        ra, rb = self.find(a), self.find(b)\n",
    "        if ra == rb: return\n",
    "        if self.r[ra] < self.r[rb]:\n",
    "            self.p[ra] = rb\n",
    "        elif self.r[ra] > self.r[rb]:\n",
    "            self.p[rb] = ra\n",
    "        else:\n",
    "            self.p[rb] = ra; self.r[ra] += 1\n",
    "\n",
    "N = len(cand_coords)\n",
    "idx_map = {rc:i for i, rc in enumerate(cand_coords)}\n",
    "cand_set = set(cand_coords)\n",
    "dsu = DSU(N)\n",
    "nbrs = [(dr, dc) for dr in (-1,0,1) for dc in (-1,0,1) if not (dr==0 and dc==0)]\n",
    "\n",
    "for i, (r, c) in enumerate(cand_coords):\n",
    "    for dr, dc in nbrs:\n",
    "        nr, nc = r+dr, c+dc\n",
    "        if (nr, nc) in cand_set:\n",
    "            dsu.union(i, idx_map[(nr, nc)])\n",
    "\n",
    "groups = {}\n",
    "for i in range(N):\n",
    "    root_i = dsu.find(i)\n",
    "    groups.setdefault(root_i, []).append(i)\n",
    "\n",
    "with rasterio.open(acc_tif) as r_acc:\n",
    "    acc = r_acc.read(1)\n",
    "    acc_nodata = r_acc.nodata\n",
    "\n",
    "selected_rc = []\n",
    "for root_i, members in groups.items():\n",
    "    best_rc, best_val = None, -1\n",
    "    for i in members:\n",
    "        rr, cc = cand_coords[i]\n",
    "        val = acc[rr, cc]\n",
    "        if acc_nodata is not None and val == acc_nodata:\n",
    "            continue\n",
    "        if val > best_val:\n",
    "            best_val = val; best_rc = (rr, cc)\n",
    "    if best_rc is None:\n",
    "        best_rc = cand_coords[members[0]]\n",
    "    selected_rc.append(best_rc)\n",
    "\n",
    "print(f\"‚úÖ Clustered outlets (one per mouth): {len(selected_rc)}\")\n",
    "\n",
    "if not selected_rc:\n",
    "    raise RuntimeError(\"No clustered outlets found. Increase threshold or verify DIR/ACC.\")\n",
    "\n",
    "# 8) Rasterize pour-points (unique IDs)\n",
    "pp_arr = np.zeros((H, W), dtype=np.int32)\n",
    "for i, (rr, cc) in enumerate(selected_rc, start=1):\n",
    "    pp_arr[rr, cc] = i\n",
    "\n",
    "profile_pp = profile.copy()\n",
    "profile_pp.update(dtype=rasterio.int32, count=1, compress=\"deflate\", tiled=True, BIGTIFF=\"IF_SAFER\")\n",
    "with rasterio.open(pp_rast, \"w\", **profile_pp) as dst:\n",
    "    dst.write(pp_arr, 1)\n",
    "print(\"‚úÖ Pour-point raster (clustered):\", pp_rast)\n",
    "\n",
    "# 9) Watershed per clustered outlet (ESRI D8)\n",
    "ok_w = wbt.watershed(d8_pntr=str(dir_tif), pour_pts=str(pp_rast), output=str(ws_tif), esri_pntr=True)\n",
    "print(\"‚úÖ Watersheds by clustered outlets:\", ok_w, \"‚Üí\", ws_tif)\n",
    "\n",
    "# 10) Polygonize to SHP (Whitebox), then write GPKG via pyogrio (no Fiona)\n",
    "ok_p = wbt.raster_to_vector_polygons(i=str(ws_tif), output=str(ws_shp))\n",
    "print(\"‚úÖ Polygons (SHP):\", ok_p, \"‚Üí\", ws_shp)\n",
    "\n",
    "gdf = pyogrio.read_dataframe(str(ws_shp))\n",
    "if gdf.crs is None:\n",
    "    with rasterio.open(ws_tif) as rt:\n",
    "        gdf.set_crs(rt.crs, inplace=True)\n",
    "pyogrio.write_dataframe(\n",
    "    gdf,\n",
    "    str(ws_gpkg),\n",
    "    layer=\"watersheds\",\n",
    "    driver=\"GPKG\",\n",
    "    append=False\n",
    ")\n",
    "print(\"‚úÖ GeoPackage written (pyogrio):\", ws_gpkg)\n",
    "try:\n",
    "    print(\"Layers:\", pyogrio.list_layers(str(ws_gpkg)))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# 11) Count unique watersheds\n",
    "with rasterio.open(ws_tif) as r:\n",
    "    WZ = r.read(1)\n",
    "    nd = r.nodata\n",
    "    n_ws = np.unique(WZ[WZ != nd]).size\n",
    "print(\"üßÆ Unique watersheds (clustered):\", n_ws)\n",
    "\n",
    "gc.collect()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a661fc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DIR/ACC aligned: 7800x5400 | CRS=EPSG:4326\n",
      "./whitebox_tools --run=\"ExtractStreams\" --wd=\"/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out\" --flow_accum='/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/as_acc_Bhutan_and_buffer.tif' --output='/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/streams.tif' --threshold='10000' -v --compress_rasters=False\n",
      "\n",
      "*****************************\n",
      "* Welcome to ExtractStreams *\n",
      "* Powered by WhiteboxTools  *\n",
      "* www.whiteboxgeo.com       *\n",
      "*****************************\n",
      "Reading data...\n",
      "Progress: 0%\n",
      "Progress: 1%\n",
      "Progress: 2%\n",
      "Progress: 3%\n",
      "Progress: 4%\n",
      "Progress: 5%\n",
      "Progress: 6%\n",
      "Progress: 7%\n",
      "Progress: 8%\n",
      "Progress: 9%\n",
      "Progress: 10%\n",
      "Progress: 11%\n",
      "Progress: 12%\n",
      "Progress: 13%\n",
      "Progress: 14%\n",
      "Progress: 15%\n",
      "Progress: 16%\n",
      "Progress: 17%\n",
      "Progress: 18%\n",
      "Progress: 19%\n",
      "Progress: 20%\n",
      "Progress: 21%\n",
      "Progress: 22%\n",
      "Progress: 23%\n",
      "Progress: 24%\n",
      "Progress: 25%\n",
      "Progress: 26%\n",
      "Progress: 27%\n",
      "Progress: 28%\n",
      "Progress: 29%\n",
      "Progress: 30%\n",
      "Progress: 31%\n",
      "Progress: 32%\n",
      "Progress: 33%\n",
      "Progress: 34%\n",
      "Progress: 35%\n",
      "Progress: 36%\n",
      "Progress: 37%\n",
      "Progress: 38%\n",
      "Progress: 39%\n",
      "Progress: 40%\n",
      "Progress: 41%\n",
      "Progress: 42%\n",
      "Progress: 43%\n",
      "Progress: 44%\n",
      "Progress: 45%\n",
      "Progress: 46%\n",
      "Progress: 47%\n",
      "Progress: 48%\n",
      "Progress: 49%\n",
      "Progress: 50%\n",
      "Progress: 51%\n",
      "Progress: 52%\n",
      "Progress: 53%\n",
      "Progress: 54%\n",
      "Progress: 55%\n",
      "Progress: 56%\n",
      "Progress: 57%\n",
      "Progress: 58%\n",
      "Progress: 59%\n",
      "Progress: 60%\n",
      "Progress: 61%\n",
      "Progress: 62%\n",
      "Progress: 63%\n",
      "Progress: 64%\n",
      "Progress: 65%\n",
      "Progress: 66%\n",
      "Progress: 67%\n",
      "Progress: 68%\n",
      "Progress: 69%\n",
      "Progress: 70%\n",
      "Progress: 71%\n",
      "Progress: 72%\n",
      "Progress: 73%\n",
      "Progress: 74%\n",
      "Progress: 75%\n",
      "Progress: 76%\n",
      "Progress: 77%\n",
      "Progress: 78%\n",
      "Progress: 79%\n",
      "Progress: 80%\n",
      "Progress: 81%\n",
      "Progress: 82%\n",
      "Progress: 83%\n",
      "Progress: 84%\n",
      "Progress: 85%\n",
      "Progress: 86%\n",
      "Progress: 87%\n",
      "Progress: 88%\n",
      "Progress: 89%\n",
      "Progress: 90%\n",
      "Progress: 91%\n",
      "Progress: 92%\n",
      "Progress: 93%\n",
      "Progress: 94%\n",
      "Progress: 95%\n",
      "Progress: 96%\n",
      "Progress: 97%\n",
      "Progress: 98%\n",
      "Progress: 99%\n",
      "Progress: 100%\n",
      "Saving data...\n",
      "Output file written\n",
      "Elapsed Time (excluding I/O): 0.334s\n",
      "‚úÖ Streams: 0 ‚Üí /home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/streams.tif\n",
      "üîé Boundary outlet candidates (raw): 8440\n",
      "‚úÖ After ACC filter (‚â• 20000 cells): 47\n",
      "‚úÖ After proximity merge (‚â§ 4px): 47\n",
      "‚úÖ Pour-point raster: /home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/auto_pour_points_filtered_merged.tif\n",
      "./whitebox_tools --run=\"Watershed\" --wd=\"/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out\" --d8_pntr='/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/as_dir_Bhutan_and_buffer.tif' --pour_pts='/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/auto_pour_points_filtered_merged.tif' --output='/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_filtered_merged.tif' --esri_pntr -v --compress_rasters=False\n",
      "\n",
      "****************************\n",
      "* Welcome to Watershed     *\n",
      "* Powered by WhiteboxTools *\n",
      "* www.whiteboxgeo.com      *\n",
      "****************************\n",
      "Reading data...\n",
      "Initializing: 0%\n",
      "Initializing: 1%\n",
      "Initializing: 2%\n",
      "Initializing: 3%\n",
      "Initializing: 4%\n",
      "Initializing: 5%\n",
      "Initializing: 6%\n",
      "Initializing: 7%\n",
      "Initializing: 8%\n",
      "Initializing: 9%\n",
      "Initializing: 10%\n",
      "Initializing: 11%\n",
      "Initializing: 12%\n",
      "Initializing: 13%\n",
      "Initializing: 14%\n",
      "Initializing: 15%\n",
      "Initializing: 16%\n",
      "Initializing: 17%\n",
      "Initializing: 18%\n",
      "Initializing: 19%\n",
      "Initializing: 20%\n",
      "Initializing: 21%\n",
      "Initializing: 22%\n",
      "Initializing: 23%\n",
      "Initializing: 24%\n",
      "Initializing: 25%\n",
      "Initializing: 26%\n",
      "Initializing: 27%\n",
      "Initializing: 28%\n",
      "Initializing: 29%\n",
      "Initializing: 30%\n",
      "Initializing: 31%\n",
      "Initializing: 32%\n",
      "Initializing: 33%\n",
      "Initializing: 34%\n",
      "Initializing: 35%\n",
      "Initializing: 36%\n",
      "Initializing: 37%\n",
      "Initializing: 38%\n",
      "Initializing: 39%\n",
      "Initializing: 40%\n",
      "Initializing: 41%\n",
      "Initializing: 42%\n",
      "Initializing: 43%\n",
      "Initializing: 44%\n",
      "Initializing: 45%\n",
      "Initializing: 46%\n",
      "Initializing: 47%\n",
      "Initializing: 48%\n",
      "Initializing: 49%\n",
      "Initializing: 50%\n",
      "Initializing: 51%\n",
      "Initializing: 52%\n",
      "Initializing: 53%\n",
      "Initializing: 54%\n",
      "Initializing: 55%\n",
      "Initializing: 56%\n",
      "Initializing: 57%\n",
      "Initializing: 58%\n",
      "Initializing: 59%\n",
      "Initializing: 60%\n",
      "Initializing: 61%\n",
      "Initializing: 62%\n",
      "Initializing: 63%\n",
      "Initializing: 64%\n",
      "Initializing: 65%\n",
      "Initializing: 66%\n",
      "Initializing: 67%\n",
      "Initializing: 68%\n",
      "Initializing: 69%\n",
      "Initializing: 70%\n",
      "Initializing: 71%\n",
      "Initializing: 72%\n",
      "Initializing: 73%\n",
      "Initializing: 74%\n",
      "Initializing: 75%\n",
      "Initializing: 76%\n",
      "Initializing: 77%\n",
      "Initializing: 78%\n",
      "Initializing: 79%\n",
      "Initializing: 80%\n",
      "Initializing: 81%\n",
      "Initializing: 82%\n",
      "Initializing: 83%\n",
      "Initializing: 84%\n",
      "Initializing: 85%\n",
      "Initializing: 86%\n",
      "Initializing: 87%\n",
      "Initializing: 88%\n",
      "Initializing: 89%\n",
      "Initializing: 90%\n",
      "Initializing: 91%\n",
      "Initializing: 92%\n",
      "Initializing: 93%\n",
      "Initializing: 94%\n",
      "Initializing: 95%\n",
      "Initializing: 96%\n",
      "Initializing: 97%\n",
      "Initializing: 98%\n",
      "Initializing: 99%\n",
      "Initializing: 100%\n",
      "Progress: 0%\n",
      "Progress: 1%\n",
      "Progress: 2%\n",
      "Progress: 3%\n",
      "Progress: 4%\n",
      "Progress: 5%\n",
      "Progress: 6%\n",
      "Progress: 7%\n",
      "Progress: 8%\n",
      "Progress: 9%\n",
      "Progress: 10%\n",
      "Progress: 11%\n",
      "Progress: 12%\n",
      "Progress: 13%\n",
      "Progress: 14%\n",
      "Progress: 15%\n",
      "Progress: 16%\n",
      "Progress: 17%\n",
      "Progress: 18%\n",
      "Progress: 19%\n",
      "Progress: 20%\n",
      "Progress: 21%\n",
      "Progress: 22%\n",
      "Progress: 23%\n",
      "Progress: 24%\n",
      "Progress: 25%\n",
      "Progress: 26%\n",
      "Progress: 27%\n",
      "Progress: 28%\n",
      "Progress: 29%\n",
      "Progress: 30%\n",
      "Progress: 31%\n",
      "Progress: 32%\n",
      "Progress: 33%\n",
      "Progress: 34%\n",
      "Progress: 35%\n",
      "Progress: 36%\n",
      "Progress: 37%\n",
      "Progress: 38%\n",
      "Progress: 39%\n",
      "Progress: 40%\n",
      "Progress: 41%\n",
      "Progress: 42%\n",
      "Progress: 43%\n",
      "Progress: 44%\n",
      "Progress: 45%\n",
      "Progress: 46%\n",
      "Progress: 47%\n",
      "Progress: 48%\n",
      "Progress: 49%\n",
      "Progress: 50%\n",
      "Progress: 51%\n",
      "Progress: 52%\n",
      "Progress: 53%\n",
      "Progress: 54%\n",
      "Progress: 55%\n",
      "Progress: 56%\n",
      "Progress: 57%\n",
      "Progress: 58%\n",
      "Progress: 59%\n",
      "Progress: 60%\n",
      "Progress: 61%\n",
      "Progress: 62%\n",
      "Progress: 63%\n",
      "Progress: 64%\n",
      "Progress: 65%\n",
      "Progress: 66%\n",
      "Progress: 67%\n",
      "Progress: 68%\n",
      "Progress: 69%\n",
      "Progress: 70%\n",
      "Progress: 71%\n",
      "Progress: 72%\n",
      "Progress: 73%\n",
      "Progress: 74%\n",
      "Progress: 75%\n",
      "Progress: 76%\n",
      "Progress: 77%\n",
      "Progress: 78%\n",
      "Progress: 79%\n",
      "Progress: 80%\n",
      "Progress: 81%\n",
      "Progress: 82%\n",
      "Progress: 83%\n",
      "Progress: 84%\n",
      "Progress: 85%\n",
      "Progress: 86%\n",
      "Progress: 87%\n",
      "Progress: 88%\n",
      "Progress: 89%\n",
      "Progress: 90%\n",
      "Progress: 91%\n",
      "Progress: 92%\n",
      "Progress: 93%\n",
      "Progress: 94%\n",
      "Progress: 95%\n",
      "Progress: 96%\n",
      "Progress: 97%\n",
      "Progress: 98%\n",
      "Progress: 99%\n",
      "Progress: 100%\n",
      "Saving data...\n",
      "Output file written\n",
      "Elapsed Time (excluding I/O): 2.356s\n",
      "‚úÖ Watersheds: 0 ‚Üí /home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_filtered_merged.tif\n",
      "./whitebox_tools --run=\"RasterToVectorPolygons\" --wd=\"/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out\" --input='/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_filtered_merged.tif' --output='/home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_filtered_merged.shp' -v --compress_rasters=False\n",
      "\n",
      "*************************************\n",
      "* Welcome to RasterToVectorPolygons *\n",
      "* Powered by WhiteboxTools          *\n",
      "* www.whiteboxgeo.com               *\n",
      "*************************************\n",
      "Reading data...\n",
      "Clumping polygons: 0%\n",
      "Clumping polygons: 1%\n",
      "Clumping polygons: 2%\n",
      "Clumping polygons: 3%\n",
      "Clumping polygons: 4%\n",
      "Clumping polygons: 5%\n",
      "Clumping polygons: 6%\n",
      "Clumping polygons: 7%\n",
      "Clumping polygons: 8%\n",
      "Clumping polygons: 9%\n",
      "Clumping polygons: 10%\n",
      "Clumping polygons: 11%\n",
      "Clumping polygons: 12%\n",
      "Clumping polygons: 13%\n",
      "Clumping polygons: 14%\n",
      "Clumping polygons: 15%\n",
      "Clumping polygons: 16%\n",
      "Clumping polygons: 17%\n",
      "Clumping polygons: 18%\n",
      "Clumping polygons: 19%\n",
      "Clumping polygons: 20%\n",
      "Clumping polygons: 21%\n",
      "Clumping polygons: 22%\n",
      "Clumping polygons: 23%\n",
      "Clumping polygons: 24%\n",
      "Clumping polygons: 25%\n",
      "Clumping polygons: 26%\n",
      "Clumping polygons: 27%\n",
      "Clumping polygons: 28%\n",
      "Clumping polygons: 29%\n",
      "Clumping polygons: 30%\n",
      "Clumping polygons: 31%\n",
      "Clumping polygons: 32%\n",
      "Clumping polygons: 33%\n",
      "Clumping polygons: 34%\n",
      "Clumping polygons: 35%\n",
      "Clumping polygons: 36%\n",
      "Clumping polygons: 37%\n",
      "Clumping polygons: 38%\n",
      "Clumping polygons: 39%\n",
      "Clumping polygons: 40%\n",
      "Clumping polygons: 41%\n",
      "Clumping polygons: 42%\n",
      "Clumping polygons: 43%\n",
      "Clumping polygons: 44%\n",
      "Clumping polygons: 45%\n",
      "Clumping polygons: 46%\n",
      "Clumping polygons: 47%\n",
      "Clumping polygons: 48%\n",
      "Clumping polygons: 49%\n",
      "Clumping polygons: 50%\n",
      "Clumping polygons: 51%\n",
      "Clumping polygons: 52%\n",
      "Clumping polygons: 53%\n",
      "Clumping polygons: 54%\n",
      "Clumping polygons: 55%\n",
      "Clumping polygons: 56%\n",
      "Clumping polygons: 57%\n",
      "Clumping polygons: 58%\n",
      "Clumping polygons: 59%\n",
      "Clumping polygons: 60%\n",
      "Clumping polygons: 61%\n",
      "Clumping polygons: 62%\n",
      "Clumping polygons: 63%\n",
      "Clumping polygons: 64%\n",
      "Clumping polygons: 65%\n",
      "Clumping polygons: 66%\n",
      "Clumping polygons: 67%\n",
      "Clumping polygons: 68%\n",
      "Clumping polygons: 69%\n",
      "Clumping polygons: 70%\n",
      "Clumping polygons: 71%\n",
      "Clumping polygons: 72%\n",
      "Clumping polygons: 73%\n",
      "Clumping polygons: 74%\n",
      "Clumping polygons: 75%\n",
      "Clumping polygons: 76%\n",
      "Clumping polygons: 77%\n",
      "Clumping polygons: 78%\n",
      "Clumping polygons: 79%\n",
      "Clumping polygons: 80%\n",
      "Clumping polygons: 81%\n",
      "Clumping polygons: 82%\n",
      "Clumping polygons: 83%\n",
      "Clumping polygons: 84%\n",
      "Clumping polygons: 85%\n",
      "Clumping polygons: 86%\n",
      "Clumping polygons: 87%\n",
      "Clumping polygons: 88%\n",
      "Clumping polygons: 89%\n",
      "Clumping polygons: 90%\n",
      "Clumping polygons: 91%\n",
      "Clumping polygons: 92%\n",
      "Clumping polygons: 93%\n",
      "Clumping polygons: 94%\n",
      "Clumping polygons: 95%\n",
      "Clumping polygons: 96%\n",
      "Clumping polygons: 97%\n",
      "Clumping polygons: 98%\n",
      "Clumping polygons: 99%\n",
      "Clumping polygons: 100%\n",
      "Finding edges: 0%\n",
      "Finding edges: 1%\n",
      "Finding edges: 2%\n",
      "Finding edges: 3%\n",
      "Finding edges: 4%\n",
      "Finding edges: 5%\n",
      "Finding edges: 6%\n",
      "Finding edges: 7%\n",
      "Finding edges: 8%\n",
      "Finding edges: 9%\n",
      "Finding edges: 10%\n",
      "Finding edges: 11%\n",
      "Finding edges: 12%\n",
      "Finding edges: 13%\n",
      "Finding edges: 14%\n",
      "Finding edges: 15%\n",
      "Finding edges: 16%\n",
      "Finding edges: 17%\n",
      "Finding edges: 18%\n",
      "Finding edges: 19%\n",
      "Finding edges: 20%\n",
      "Finding edges: 21%\n",
      "Finding edges: 22%\n",
      "Finding edges: 23%\n",
      "Finding edges: 24%\n",
      "Finding edges: 25%\n",
      "Finding edges: 26%\n",
      "Finding edges: 27%\n",
      "Finding edges: 28%\n",
      "Finding edges: 29%\n",
      "Finding edges: 30%\n",
      "Finding edges: 31%\n",
      "Finding edges: 32%\n",
      "Finding edges: 33%\n",
      "Finding edges: 34%\n",
      "Finding edges: 35%\n",
      "Finding edges: 36%\n",
      "Finding edges: 37%\n",
      "Finding edges: 38%\n",
      "Finding edges: 39%\n",
      "Finding edges: 40%\n",
      "Finding edges: 41%\n",
      "Finding edges: 42%\n",
      "Finding edges: 43%\n",
      "Finding edges: 44%\n",
      "Finding edges: 45%\n",
      "Finding edges: 46%\n",
      "Finding edges: 47%\n",
      "Finding edges: 48%\n",
      "Finding edges: 49%\n",
      "Finding edges: 50%\n",
      "Finding edges: 51%\n",
      "Finding edges: 52%\n",
      "Finding edges: 53%\n",
      "Finding edges: 54%\n",
      "Finding edges: 55%\n",
      "Finding edges: 56%\n",
      "Finding edges: 57%\n",
      "Finding edges: 58%\n",
      "Finding edges: 59%\n",
      "Finding edges: 60%\n",
      "Finding edges: 61%\n",
      "Finding edges: 62%\n",
      "Finding edges: 63%\n",
      "Finding edges: 64%\n",
      "Finding edges: 65%\n",
      "Finding edges: 66%\n",
      "Finding edges: 67%\n",
      "Finding edges: 68%\n",
      "Finding edges: 69%\n",
      "Finding edges: 70%\n",
      "Finding edges: 71%\n",
      "Finding edges: 72%\n",
      "Finding edges: 73%\n",
      "Finding edges: 74%\n",
      "Finding edges: 75%\n",
      "Finding edges: 76%\n",
      "Finding edges: 77%\n",
      "Finding edges: 78%\n",
      "Finding edges: 79%\n",
      "Finding edges: 80%\n",
      "Finding edges: 81%\n",
      "Finding edges: 82%\n",
      "Finding edges: 83%\n",
      "Finding edges: 84%\n",
      "Finding edges: 85%\n",
      "Finding edges: 86%\n",
      "Finding edges: 87%\n",
      "Finding edges: 88%\n",
      "Finding edges: 89%\n",
      "Finding edges: 90%\n",
      "Finding edges: 91%\n",
      "Finding edges: 92%\n",
      "Finding edges: 93%\n",
      "Finding edges: 94%\n",
      "Finding edges: 95%\n",
      "Finding edges: 96%\n",
      "Finding edges: 97%\n",
      "Finding edges: 98%\n",
      "Finding edges: 99%\n",
      "Finding edges: 100%\n",
      "Tracing polygons: 0%\n",
      "Tracing polygons: 1%\n",
      "Tracing polygons: 2%\n",
      "Tracing polygons: 3%\n",
      "Tracing polygons: 4%\n",
      "Tracing polygons: 5%\n",
      "Tracing polygons: 6%\n",
      "Tracing polygons: 7%\n",
      "Tracing polygons: 8%\n",
      "Tracing polygons: 9%\n",
      "Tracing polygons: 10%\n",
      "Tracing polygons: 11%\n",
      "Tracing polygons: 12%\n",
      "Tracing polygons: 13%\n",
      "Tracing polygons: 14%\n",
      "Tracing polygons: 15%\n",
      "Tracing polygons: 16%\n",
      "Tracing polygons: 17%\n",
      "Tracing polygons: 18%\n",
      "Tracing polygons: 19%\n",
      "Tracing polygons: 20%\n",
      "Tracing polygons: 21%\n",
      "Tracing polygons: 22%\n",
      "Tracing polygons: 23%\n",
      "Tracing polygons: 24%\n",
      "Tracing polygons: 25%\n",
      "Tracing polygons: 26%\n",
      "Tracing polygons: 27%\n",
      "Tracing polygons: 28%\n",
      "Tracing polygons: 29%\n",
      "Tracing polygons: 30%\n",
      "Tracing polygons: 31%\n",
      "Tracing polygons: 32%\n",
      "Tracing polygons: 33%\n",
      "Tracing polygons: 34%\n",
      "Tracing polygons: 35%\n",
      "Tracing polygons: 36%\n",
      "Tracing polygons: 37%\n",
      "Tracing polygons: 38%\n",
      "Tracing polygons: 39%\n",
      "Tracing polygons: 40%\n",
      "Tracing polygons: 41%\n",
      "Tracing polygons: 42%\n",
      "Tracing polygons: 43%\n",
      "Tracing polygons: 44%\n",
      "Tracing polygons: 45%\n",
      "Tracing polygons: 46%\n",
      "Tracing polygons: 47%\n",
      "Tracing polygons: 48%\n",
      "Tracing polygons: 49%\n",
      "Tracing polygons: 50%\n",
      "Tracing polygons: 51%\n",
      "Tracing polygons: 52%\n",
      "Tracing polygons: 53%\n",
      "Tracing polygons: 54%\n",
      "Tracing polygons: 55%\n",
      "Tracing polygons: 56%\n",
      "Tracing polygons: 57%\n",
      "Tracing polygons: 58%\n",
      "Tracing polygons: 59%\n",
      "Tracing polygons: 60%\n",
      "Tracing polygons: 61%\n",
      "Tracing polygons: 62%\n",
      "Tracing polygons: 63%\n",
      "Tracing polygons: 64%\n",
      "Tracing polygons: 65%\n",
      "Tracing polygons: 66%\n",
      "Tracing polygons: 67%\n",
      "Tracing polygons: 68%\n",
      "Tracing polygons: 69%\n",
      "Tracing polygons: 70%\n",
      "Tracing polygons: 71%\n",
      "Tracing polygons: 72%\n",
      "Tracing polygons: 73%\n",
      "Tracing polygons: 74%\n",
      "Tracing polygons: 75%\n",
      "Tracing polygons: 76%\n",
      "Tracing polygons: 77%\n",
      "Tracing polygons: 78%\n",
      "Tracing polygons: 79%\n",
      "Tracing polygons: 80%\n",
      "Tracing polygons: 81%\n",
      "Tracing polygons: 82%\n",
      "Tracing polygons: 83%\n",
      "Tracing polygons: 84%\n",
      "Tracing polygons: 85%\n",
      "Tracing polygons: 86%\n",
      "Tracing polygons: 87%\n",
      "Tracing polygons: 88%\n",
      "Tracing polygons: 89%\n",
      "Tracing polygons: 90%\n",
      "Tracing polygons: 91%\n",
      "Tracing polygons: 92%\n",
      "Tracing polygons: 93%\n",
      "Tracing polygons: 94%\n",
      "Tracing polygons: 95%\n",
      "Tracing polygons: 96%\n",
      "Tracing polygons: 97%\n",
      "Tracing polygons: 98%\n",
      "Tracing polygons: 99%\n",
      "Tracing polygons: 100%\n",
      "Creating geometries: 0%\n",
      "Creating geometries: 2%\n",
      "Creating geometries: 4%\n",
      "Creating geometries: 6%\n",
      "Creating geometries: 8%\n",
      "Creating geometries: 10%\n",
      "Creating geometries: 13%\n",
      "Creating geometries: 15%\n",
      "Creating geometries: 17%\n",
      "Creating geometries: 19%\n",
      "Creating geometries: 21%\n",
      "Creating geometries: 23%\n",
      "Creating geometries: 26%\n",
      "Creating geometries: 28%\n",
      "Creating geometries: 30%\n",
      "Creating geometries: 32%\n",
      "Creating geometries: 34%\n",
      "Creating geometries: 36%\n",
      "Creating geometries: 39%\n",
      "Creating geometries: 41%\n",
      "Creating geometries: 43%\n",
      "Creating geometries: 45%\n",
      "Creating geometries: 47%\n",
      "Creating geometries: 50%\n",
      "Creating geometries: 52%\n",
      "Creating geometries: 54%\n",
      "Creating geometries: 56%\n",
      "Creating geometries: 58%\n",
      "Creating geometries: 60%\n",
      "Creating geometries: 63%\n",
      "Creating geometries: 65%\n",
      "Creating geometries: 67%\n",
      "Creating geometries: 69%\n",
      "Creating geometries: 71%\n",
      "Creating geometries: 73%\n",
      "Creating geometries: 76%\n",
      "Creating geometries: 78%\n",
      "Creating geometries: 80%\n",
      "Creating geometries: 82%\n",
      "Creating geometries: 84%\n",
      "Creating geometries: 86%\n",
      "Creating geometries: 89%\n",
      "Creating geometries: 91%\n",
      "Creating geometries: 93%\n",
      "Creating geometries: 95%\n",
      "Creating geometries: 97%\n",
      "Creating geometries: 100%\n",
      "Saving data...\n",
      "Output file written\n",
      "Elapsed Time (excluding I/O): 4.736s\n",
      "‚úÖ SHP: /home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_filtered_merged.shp\n",
      "‚úÖ GPKG: /home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_filtered_merged.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/merlin/.local/lib/python3.8/site-packages/pyogrio/raw.py:196: RuntimeWarning: /home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_filtered_merged.shp contains polygon(s) with rings with invalid winding order. Autocorrecting them, but that shapefile should be corrected using ogr2ogr for example.\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßÆ Unique watersheds: 47\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# === Rebuild clustered watersheds with outlet filtering + proximity merge ===\n",
    "# - Streams from ACC (threshold = 10,000 cells)\n",
    "# - Boundary outlet candidates (stream on outer border + ESRI-D8 points outside)\n",
    "# - Filter outlets by minimum ACC (major mouths only)\n",
    "# - Merge outlets within MERGE_RADIUS_PX (Chebyshev)\n",
    "# - Watershed per outlet; polygonize; write GPKG via pyogrio\n",
    "\n",
    "import sys, subprocess, os, gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "# Ensure pyogrio present in THIS kernel\n",
    "def ensure_package(name):\n",
    "    try:\n",
    "        __import__(name)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", name])\n",
    "\n",
    "ensure_package(\"pyogrio\")\n",
    "import pyogrio\n",
    "\n",
    "# Py3.8 shim for whitebox\n",
    "if sys.version_info < (3, 9):\n",
    "    import importlib.resources as ir\n",
    "    try:\n",
    "        import importlib_resources\n",
    "        if not hasattr(ir, \"files\"):\n",
    "            ir.files = importlib_resources.files\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "import whitebox\n",
    "wbt = whitebox.WhiteboxTools()\n",
    "\n",
    "# -------- Parameters (tune these) --------\n",
    "STREAM_THRESHOLD_CELLS = 10_000     # ACC >= this -> stream (‚âà81 km¬≤ if 0.0081 km¬≤/pixel)\n",
    "MIN_OUTLET_ACC_CELLS   = 20_000     # keep only outlets with ACC >= this (‚âà162 km¬≤)\n",
    "MERGE_RADIUS_PX        = 4          # merge outlets closer than this (Chebyshev pixels)\n",
    "# -----------------------------------------\n",
    "\n",
    "# Paths\n",
    "root = Path(\"../../data/HydroSHEDS\").resolve()\n",
    "dir_tif = (root / \"as_dir_Bhutan_and_buffer.tif\").resolve()\n",
    "acc_tif = (root / \"as_acc_Bhutan_and_buffer.tif\").resolve()\n",
    "out_dir = (root / \"bt_out\").resolve()\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "streams_tif = out_dir / \"streams.tif\"\n",
    "pp_rast     = out_dir / \"auto_pour_points_filtered_merged.tif\"\n",
    "ws_tif      = out_dir / \"watersheds_filtered_merged.tif\"\n",
    "ws_shp      = out_dir / \"watersheds_filtered_merged.shp\"\n",
    "ws_gpkg     = out_dir / \"watersheds_filtered_merged.gpkg\"\n",
    "\n",
    "def safe_remove(p: Path):\n",
    "    try:\n",
    "        if p.exists(): p.unlink()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not remove {p}: {e}\")\n",
    "\n",
    "def cleanup_shapefile(stem: Path):\n",
    "    base = stem.with_suffix(\"\")\n",
    "    for ext in (\".shp\", \".shx\", \".dbf\", \".prj\", \".cpg\", \".qmd\"):\n",
    "        safe_remove(base.with_suffix(ext))\n",
    "\n",
    "# Clean previous outputs\n",
    "for p in [streams_tif, pp_rast, ws_tif, ws_gpkg]:\n",
    "    safe_remove(p)\n",
    "cleanup_shapefile(ws_shp)\n",
    "\n",
    "# Checks & alignment\n",
    "assert dir_tif.exists() and acc_tif.exists()\n",
    "with rasterio.open(dir_tif) as rD, rasterio.open(acc_tif) as rA:\n",
    "    assert rD.crs == rA.crs\n",
    "    assert rD.transform == rA.transform\n",
    "    assert (rD.width, rD.height) == (rA.width, rA.height)\n",
    "    H, W = rD.height, rD.width\n",
    "    profile = rD.profile\n",
    "print(f\"‚úÖ DIR/ACC aligned: {W}x{H} | CRS={profile['crs']}\")\n",
    "\n",
    "wbt.work_dir = str(out_dir)\n",
    "\n",
    "# 1) Streams from ACC\n",
    "ok_s = wbt.extract_streams(flow_accum=str(acc_tif), output=str(streams_tif), threshold=STREAM_THRESHOLD_CELLS)\n",
    "print(\"‚úÖ Streams:\", ok_s, \"‚Üí\", streams_tif)\n",
    "\n",
    "# 2) Boundary outlet candidates\n",
    "with rasterio.open(dir_tif) as r_dir, rasterio.open(streams_tif) as r_str:\n",
    "    dir_arr = r_dir.read(1)\n",
    "    str_arr = r_str.read(1).astype(bool)\n",
    "\n",
    "code2offset = {1:(0,1), 2:(1,1), 4:(1,0), 8:(1,-1), 16:(0,-1), 32:(-1,-1), 64:(-1,0), 128:(-1,1)}\n",
    "\n",
    "cand = []\n",
    "# top/bottom rows\n",
    "for c in range(W):\n",
    "    for r in (0, H-1):\n",
    "        if str_arr[r, c]:\n",
    "            d = int(dir_arr[r, c])\n",
    "            if d in code2offset:\n",
    "                dr, dc = code2offset[d]\n",
    "                nr, nc = r + dr, c + dc\n",
    "                if nr < 0 or nr >= H or nc < 0 or nc >= W:\n",
    "                    cand.append((r, c))\n",
    "# left/right cols (skip corners dupes)\n",
    "for r in range(1, H-1):\n",
    "    for c in (0, W-1):\n",
    "        if str_arr[r, c]:\n",
    "            d = int(dir_arr[r, c])\n",
    "            if d in code2offset:\n",
    "                dr, dc = code2offset[d]\n",
    "                nr, nc = r + dr, c + dc\n",
    "                if nr < 0 or nr >= H or nc < 0 or nc >= W:\n",
    "                    cand.append((r, c))\n",
    "\n",
    "# dedupe\n",
    "cand = list(dict.fromkeys(cand))\n",
    "print(f\"üîé Boundary outlet candidates (raw): {len(cand)}\")\n",
    "\n",
    "# 3) Filter by minimum ACC at outlet\n",
    "with rasterio.open(acc_tif) as r_acc:\n",
    "    acc = r_acc.read(1)\n",
    "    acc_nd = r_acc.nodata\n",
    "\n",
    "def acc_val(rc):\n",
    "    v = acc[rc[0], rc[1]]\n",
    "    return -1 if (acc_nd is not None and v == acc_nd) else v\n",
    "\n",
    "cand2 = [rc for rc in cand if acc_val(rc) >= MIN_OUTLET_ACC_CELLS]\n",
    "print(f\"‚úÖ After ACC filter (‚â• {MIN_OUTLET_ACC_CELLS} cells): {len(cand2)}\")\n",
    "\n",
    "# 4) Merge outlets within MERGE_RADIUS_PX (Chebyshev)\n",
    "#    DSU over points; union if max(|dr|,|dc|) <= MERGE_RADIUS_PX\n",
    "class DSU:\n",
    "    def __init__(self, n):\n",
    "        self.p = list(range(n)); self.r = [0]*n\n",
    "    def find(self, x):\n",
    "        while self.p[x] != x:\n",
    "            self.p[x] = self.p[self.p[x]]\n",
    "            x = self.p[x]\n",
    "        return x\n",
    "    def union(self, a, b):\n",
    "        ra, rb = self.find(a), self.find(b)\n",
    "        if ra == rb: return\n",
    "        if self.r[ra] < self.r[rb]:\n",
    "            self.p[ra] = rb\n",
    "        elif self.r[ra] > self.r[rb]:\n",
    "            self.p[rb] = ra\n",
    "        else:\n",
    "            self.p[rb] = ra; self.r[ra] += 1\n",
    "\n",
    "N = len(cand2)\n",
    "dsu = DSU(N)\n",
    "for i in range(N):\n",
    "    r1, c1 = cand2[i]\n",
    "    # check only j>i to reduce work\n",
    "    for j in range(i+1, N):\n",
    "        r2, c2 = cand2[j]\n",
    "        if max(abs(r1-r2), abs(c1-c2)) <= MERGE_RADIUS_PX:\n",
    "            dsu.union(i, j)\n",
    "\n",
    "groups = {}\n",
    "for i in range(N):\n",
    "    root = dsu.find(i)\n",
    "    groups.setdefault(root, []).append(i)\n",
    "\n",
    "selected = []\n",
    "for root, idxs in groups.items():\n",
    "    # pick point with max ACC\n",
    "    best_rc, best_v = None, -1\n",
    "    for i in idxs:\n",
    "        rc = cand2[i]\n",
    "        v = acc_val(rc)\n",
    "        if v > best_v:\n",
    "            best_v, best_rc = v, rc\n",
    "    selected.append(best_rc)\n",
    "\n",
    "print(f\"‚úÖ After proximity merge (‚â§ {MERGE_RADIUS_PX}px): {len(selected)}\")\n",
    "\n",
    "# 5) Rasterize pour points\n",
    "pp_arr = np.zeros((H, W), dtype=np.int32)\n",
    "for i, (rr, cc) in enumerate(selected, start=1):\n",
    "    pp_arr[rr, cc] = i\n",
    "\n",
    "profile_pp = profile.copy()\n",
    "profile_pp.update(dtype=rasterio.int32, count=1, compress=\"deflate\", tiled=True, BIGTIFF=\"IF_SAFER\")\n",
    "with rasterio.open(pp_rast, \"w\", **profile_pp) as dst:\n",
    "    dst.write(pp_arr, 1)\n",
    "print(\"‚úÖ Pour-point raster:\", pp_rast)\n",
    "\n",
    "# 6) Watersheds\n",
    "ok_w = wbt.watershed(d8_pntr=str(dir_tif), pour_pts=str(pp_rast), output=str(ws_tif), esri_pntr=True)\n",
    "print(\"‚úÖ Watersheds:\", ok_w, \"‚Üí\", ws_tif)\n",
    "\n",
    "# 7) Polygonize + GPKG\n",
    "wbt.raster_to_vector_polygons(i=str(ws_tif), output=str(ws_shp))\n",
    "print(\"‚úÖ SHP:\", ws_shp)\n",
    "\n",
    "gdf = pyogrio.read_dataframe(str(ws_shp))\n",
    "if gdf.crs is None:\n",
    "    with rasterio.open(ws_tif) as rt:\n",
    "        gdf.set_crs(rt.crs, inplace=True)\n",
    "pyogrio.write_dataframe(gdf, str(ws_gpkg), layer=\"watersheds\", driver=\"GPKG\", append=False)\n",
    "print(\"‚úÖ GPKG:\", ws_gpkg)\n",
    "\n",
    "# 8) Count watersheds\n",
    "with rasterio.open(ws_tif) as r:\n",
    "    WZ = r.read(1)\n",
    "    nd = r.nodata\n",
    "    n_ws = np.unique(WZ[WZ != nd]).size\n",
    "print(\"üßÆ Unique watersheds:\", n_ws)\n",
    "\n",
    "gc.collect()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c2821c",
   "metadata": {},
   "source": [
    "1) Compute basin areas and export a summary table\n",
    "\n",
    "Adds area_km2 and a robust ws_id to the GPKG + a CSV summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c5c048d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Updated GPKG with ws_id + area_km2: /home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_filtered_merged.gpkg\n",
      "‚úÖ Summary CSV: /home/merlin/Bhutan-Climate-Change/bhutan_climate_modeling/bhutan_climate_modeling/data/HydroSHEDS/bt_out/watersheds_filtered_merged_summary.csv\n",
      "üßÆ Basins: 47  | area_km2 stats:  2.127651543268542 ‚Üí 143958.44097443993\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pyogrio\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "root   = Path(\"../../data/HydroSHEDS\").resolve()\n",
    "outdir = root / \"bt_out\"\n",
    "gpkg   = outdir / \"watersheds_filtered_merged.gpkg\"\n",
    "layer  = \"watersheds\"\n",
    "summary_csv = outdir / \"watersheds_filtered_merged_summary.csv\"\n",
    "\n",
    "# Read polygons\n",
    "gdf = pyogrio.read_dataframe(gpkg, layer=layer)\n",
    "\n",
    "# Ensure CRS is present; if missing, copy from raster\n",
    "if gdf.crs is None:\n",
    "    with rasterio.open(outdir / \"watersheds_filtered_merged.tif\") as r:\n",
    "        gdf = gdf.set_crs(r.crs)\n",
    "\n",
    "# Try to find an integer ID column from Whitebox (commonly 'value' or 'FID')\n",
    "id_col = None\n",
    "for cand in [\"value\", \"VALUE\", \"fid\", \"FID\", \"Id\", \"ID\"]:\n",
    "    if cand in gdf.columns:\n",
    "        id_col = cand\n",
    "        break\n",
    "if id_col is None:\n",
    "    # Fall back to index-based ID\n",
    "    gdf[\"ws_id\"] = gdf.index.astype(int) + 1\n",
    "else:\n",
    "    gdf = gdf.rename(columns={id_col: \"ws_id\"})\n",
    "    gdf[\"ws_id\"] = gdf[\"ws_id\"].astype(int)\n",
    "\n",
    "# Compute area in km¬≤ using an equal-area projection\n",
    "gdf_eq = gdf.to_crs(\"EPSG:6933\")  # World Cylindrical Equal Area\n",
    "gdf[\"area_km2\"] = gdf_eq.geometry.area.values / 1_000_000.0\n",
    "\n",
    "# Write back to GPKG (overwriting layer) and CSV summary\n",
    "pyogrio.write_dataframe(gdf, gpkg, layer=layer, driver=\"GPKG\", append=False)\n",
    "gdf[[\"ws_id\", \"area_km2\"]].to_csv(summary_csv, index=False)\n",
    "\n",
    "print(\"‚úÖ Updated GPKG with ws_id + area_km2:\", gpkg)\n",
    "print(\"‚úÖ Summary CSV:\", summary_csv)\n",
    "print(\"üßÆ Basins:\", len(gdf), \" | area_km2 stats: \",\n",
    "      float(gdf[\"area_km2\"].min()), \"‚Üí\", float(gdf[\"area_km2\"].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0315d29",
   "metadata": {},
   "source": [
    "2) Map any (lon, lat) points to watershed IDs (your ‚Äúdictionary‚Äù)\n",
    "\n",
    "Takes a CSV of points and adds the ws_id from the watershed raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7552a355",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/your_points.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m out_csv \u001b[38;5;241m=\u001b[39m Path(points_csv)\u001b[38;5;241m.\u001b[39mwith_name(Path(points_csv)\u001b[38;5;241m.\u001b[39mstem \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_with_ws_id.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Load points\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m}\u001b[38;5;241m.\u001b[39missubset(df\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSV must have columns: longitude, latitude\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Sample watershed raster at point locations (lon/lat order for EPSG:4326)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/your_points.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.sample import sample_gen\n",
    "from pathlib import Path\n",
    "\n",
    "# Inputs\n",
    "points_csv = \"../../data/your_points.csv\"  # <- change to your file (must have 'longitude','latitude')\n",
    "root   = Path(\"../../data/HydroSHEDS\").resolve()\n",
    "ws_tif = root / \"bt_out\" / \"watersheds_filtered_merged.tif\"\n",
    "out_csv = Path(points_csv).with_name(Path(points_csv).stem + \"_with_ws_id.csv\")\n",
    "\n",
    "# Load points\n",
    "df = pd.read_csv(points_csv)\n",
    "assert {\"longitude\",\"latitude\"}.issubset(df.columns), \"CSV must have columns: longitude, latitude\"\n",
    "\n",
    "# Sample watershed raster at point locations (lon/lat order for EPSG:4326)\n",
    "with rasterio.open(ws_tif) as r:\n",
    "    assert r.crs.to_string() == \"EPSG:4326\", \"Expecting EPSG:4326 raster\"\n",
    "    coords = list(zip(df[\"longitude\"].values, df[\"latitude\"].values))\n",
    "    vals = list(r.sample(coords))  # each is a 1-length array\n",
    "\n",
    "ws_vals = np.array([v[0] for v in vals])\n",
    "# Treat NoData as NaN\n",
    "with rasterio.open(ws_tif) as r:\n",
    "    nodata = r.nodata\n",
    "ws_id = ws_vals.astype(\"float64\")\n",
    "if nodata is not None:\n",
    "    ws_id = np.where(ws_id == nodata, np.nan, ws_id)\n",
    "df[\"ws_id\"] = ws_id.astype(\"Int64\")  # pandas nullable int\n",
    "\n",
    "# Save\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"‚úÖ Points mapped to watersheds:\", out_csv)\n",
    "\n",
    "# Quick QA: how many points per basin?\n",
    "counts = df[\"ws_id\"].value_counts(dropna=True).sort_index()\n",
    "print(\"üßÆ Points per ws_id (head):\")\n",
    "print(counts.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
